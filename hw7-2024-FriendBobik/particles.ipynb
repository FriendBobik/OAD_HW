{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import tf2onnx\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А тут время интересных историй\n",
    "Я как вроде умный человек потыкался в момент выполнения кода, сколько же задействуестья ядер (ну скорее потоков, но не будем душить) процессора оказалось что всего одно. Мне стало очень грусно, и я подумал а что если обучать на встроенном видео ядре, оно же сможет распаралелить и оооочень быстро посчитать, на проце условная моделька считалась 45 секунд, я разобрался и смог запустить GPU (встройка в m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого стало всего 19, но минут... Эхххх https://www.youtube.com/watch?v=zKwYz83DFKY\n",
    "\n",
    "Ну ладно, если будет время, я ещё попробую на другом пк с дискретной картой. Много часов спустя, я могу сказать что я несправился\n",
    "\n",
    "Ещё была идея взять нормальный человеческий гугл колаб, но чет я зажал 10 USD\n",
    "\n",
    "Да да да, это всё избыточно, я поэтосамовал на такие идеи примерно 6 часов, но как говорит мой друг, это не ~~военное~~ преступление если тебе было весело. Мне было весело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Список колонок в выборках\n",
    "\n",
    "Здесь **Spd** обозначает Scintillating Pad Detector (сцинтилляционный детектор), **Prs** - Preshower (предшоуэрный детектор), **Ecal** - электромагнитный калориметр, **Hcal** - адронный калориметр, **Brem** обозначает следы частиц, отклоненных детектором.\n",
    "\n",
    "- ID - идентификатор для треков (присутствует только в тестовом файле для целей отправки)\n",
    "- Label - строковое значение, обозначающее типы частиц. Может принимать значения \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" и \"Ghost\". Эта колонка отсутствует в тестовом файле.\n",
    "- FlagSpd - флаг (0 или 1), если реконструированный трек проходит через Spd\n",
    "- FlagPrs - флаг (0 или 1), если реконструированный трек проходит через Prs\n",
    "- FlagBrem - флаг (0 или 1), если реконструированный трек проходит через Brem\n",
    "- FlagEcal - флаг (0 или 1), если реконструированный трек проходит через Ecal\n",
    "- FlagHcal - флаг (0 или 1), если реконструированный трек проходит через Hcal\n",
    "- FlagRICH1 - флаг (0 или 1), если реконструированный трек проходит через первый детектор RICH\n",
    "- FlagRICH2 - флаг (0 или 1), если реконструированный трек проходит через второй детектор RICH\n",
    "- FlagMuon - флаг (0 или 1), если реконструированный трек проходит через мюонные станции (Muon)\n",
    "- SpdE - энергия, связанная с треком в Spd\n",
    "- PrsE - энергия, связанная с треком в Prs\n",
    "- EcalE - энергия, связанная с треком в Ecal\n",
    "- HcalE - энергия, связанная с треком в Hcal\n",
    "- PrsDLLbeElectron - дельта логарифма правдоподобия для кандидата в частицы быть электроном, используя информацию из Prs\n",
    "- BremDLLbeElectron - дельта логарифма правдоподобия для кандидата в частицы быть электроном, используя информацию из Brem\n",
    "- TrackP - импульс частицы\n",
    "- TrackPt - поперечный импульс частицы\n",
    "- TrackNDoFSubdetector1 - число степеней свободы для подгонки трека, используя попадания в субдетектор1\n",
    "- TrackQualitySubdetector1 - качество подгонки трека (chi2), используя попадания в субдетектор1\n",
    "- TrackNDoFSubdetector2 - число степеней свободы для подгонки трека, используя попадания в субдетектор2\n",
    "- TrackQualitySubdetector2 - качество подгонки трека (chi2), используя попадания в субдетектор2\n",
    "- TrackNDoF - число степеней свободы для подгонки трека, используя попадания во все субдетекторы\n",
    "- TrackQualityPerNDoF - качество подгонки трека (chi2) на степень свободы\n",
    "- TrackDistanceToZ - расстояние между треком и осью z (осью пучка)\n",
    "- Calo2dFitQuality - качество 2D подгонки кластеров в калориметре\n",
    "- Calo3dFitQuality - качество 3D подгонки в калориметре с предположением, что частица была электроном\n",
    "- EcalDLLbeElectron - дельта логарифма правдоподобия для кандидата в частицы быть электроном, используя информацию из Ecal\n",
    "- EcalDLLbeMuon - дельта логарифма правдоподобия для кандидата в частицы быть мюоном, используя информацию из Ecal\n",
    "- EcalShowerLongitudinalParameter - продольный параметр шауэра в Ecal\n",
    "- HcalDLLbeElectron - дельта логарифма правдоподобия для кандидата в частицы быть электроном, используя информацию из Hcal\n",
    "- HcalDLLbeMuon - дельта логарифма правдоподобия для кандидата в частицы быть мюоном, используя информацию из Hcal\n",
    "- RICHpFlagElectron - флаг (0 или 1), если импульс больше порога для электронов, чтобы произвести свет Черенкова\n",
    "- RICHpFlagProton - флаг (0 или 1), если импульс больше порога для протонов, чтобы произвести свет Черенкова\n",
    "- RICHpFlagPion - флаг (0 или 1), если импульс больше порога для пионов, чтобы произвести свет Черенкова\n",
    "- RICHpFlagKaon - флаг (0 или 1), если импульс больше порога для каонов, чтобы произвести свет Черенкова\n",
    "- RICHpFlagMuon - флаг (0 или 1), если импульс больше порога для мюонов, чтобы произвести свет Черенкова\n",
    "- RICH_DLLbeBCK - дельта логарифма правдоподобия для кандидата в частицы быть фоновым, используя информацию из RICH\n",
    "- RICH_DLLbeKaon - дельта логарифма правдоподобия для кандидата в частицы быть каоном, используя информацию из RICH\n",
    "- RICH_DLLbeElectron - дельта логарифма правдоподобия для кандидата в частицы быть электроном, используя информацию из RICH\n",
    "- RICH_DLLbeMuon - дельта логарифма правдоподобия для кандидата в частицы быть мюоном, используя информацию из RICH\n",
    "- RICH_DLLbeProton - дельта логарифма правдоподобия для кандидата в частицы быть протоном, используя информацию из RICH\n",
    "- MuonFlag - мюонный флаг (является ли этот трек мюоном), который определяется по мюонным станциям\n",
    "- MuonLooseFlag - мюонный флаг (является ли этот трек мюоном), который определяется по мюонным станциям с использованием более слабых критериев\n",
    "- MuonLLbeBCK - логарифм правдоподобия для кандидата в частицы не быть мюоном, используя информацию из мюонных станций\n",
    "- MuonLLbeMuon - логарифм правдоподобия для кандидата в частицы быть мюоном, используя информацию из мюонных станций\n",
    "- DLLelectron - дельта логарифма правдоподобия для кандидата в частицы быть электроном, используя информацию из всех субдетекторов\n",
    "- DLLmuon - дельта логарифма правдоподобия для кандидата в частицы быть мюоном, используя информацию из всех субдетекторов\n",
    "- DLLkaon - дельта логарифма правдоподобия для кандидата в частицы быть каоном, используя информацию из всех субдетекторов\n",
    "- DLLproton - дельта логарифма правдоподобия для кандидата в частицы быть протоном, используя информацию из всех субдетекторов\n",
    "- GhostProbability - вероятность для кандидата в частицы быть призрачным треком. Эта переменная является выходом классификационной модели, используемой в алгоритме трекинга.\n",
    "\n",
    "Дельта логарифма правдоподобия в описаниях признаков означает разницу между логарифмом правдоподобия для гипотезы массы, что данный трек создан некоторой частицей (например, электроном) и логарифмом правдоподобия для гипотезы массы, что данный трек создан пионом (то есть DLLpion = 0, и поэтому у нас нет этих колонок). Это сделано потому, что большинство треков (~80%) оставлены пионами, и на практике нам действительно нужно различать другие частицы от пионов. Иными словами, нулевая гипотеза заключается в том, что частица является пионом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(data.loc[:, data.columns != 'Label'], dtype=np.float32)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.Label)\n",
    "y = le.transform(data.Label).astype(np.float32)\n",
    "labels = np.array(le.classes_, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.array([(data.Label == l).sum() for l in labels])\n",
    "plt.bar(np.arange(len(labels)), count / np.sum(count))\n",
    "plt.xticks(np.arange(len(labels)), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы сбалансированы, ура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM  = x_train.shape[1]\n",
    "HIDDEN_DIM = 100 \n",
    "# ну вообще, HIDDEN_DIM это тоже гиперпараметр, и его тоже можно подбирать\n",
    "# Например по кросс-валидации, но опять же, это избыточно, потому что AUC-ROC 0.97 и так можно получить\n",
    "OUTPUT_DIM = len(labels)\n",
    "\n",
    "# Ну а INPUT_DIM и OUTPUT_DIM это очевидно, размеры входа и выхода, что константа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, hidden_dim, output_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(hidden_dim // 2, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(output_dim, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['AUC', 'accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, tf.keras.utils.to_categorical(y_train, num_classes=len(labels)),\n",
    "        epochs=10, batch_size=16,\n",
    "        validation_data=(x_test, tf.keras.utils.to_categorical(y_test, num_classes=len(labels))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (tf.TensorSpec((None, INPUT_DIM), tf.float32, name=\"input\"),)\n",
    "output_path = \"particles.onnx\"\n",
    "model.output_names = ['output'] # добавим такой костыль, чтобы tf2onnx не ругался, а то чет хз\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_score, labels,saving=True):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    \n",
    "    plt.figure()\n",
    "    for i, label in enumerate(labels):\n",
    "        fpr[label], tpr[label], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[label] = auc(fpr[label], tpr[label])\n",
    "        plt.plot(fpr[label], tpr[label], lw=2, label=f'{label} (AUC = {roc_auc[label]:.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if saving:\n",
    "        plt.savefig('roc.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('train.png')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap=plt.cm.Blues)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_json(metrics, filename='particles.json'):\n",
    "    data = {\"test_auc\": metrics}\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну в целом моделькак хорошая, как я понимаю даже на малом количестве шагов (шага 4) она даст норм результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=len(labels))\n",
    "y_score = model.predict(x_test)\n",
    "y_pred = np.argmax(y_score, axis=1)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = plot_roc_curve(y_test_cat, y_score, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics_to_json(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте убедимся что всё открывается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я что-то добавил новый файл, и оперативке поплохело, ну давайте уберемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del history\n",
    "del x_train, x_test, y_train, y_test\n",
    "gc.collect() # вероятно есть какой-то более умпный способ освободить память, но пока и так работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"test.csv\", index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.asarray(data_test, dtype=np.float32)\n",
    "sess = rt.InferenceSession(\"particles.onnx\")\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "print(\"Inputs: {}\".format([x.name for x in sess.get_inputs()]))\n",
    "print(\"Outputs: {}\".format([x.name for x in sess.get_outputs()]))\n",
    "\n",
    "pred = sess.run([label_name], {input_name: x})\n",
    "np.savetxt(\"predict.csv\", pred[0], delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЭЭЭЭ ну в целом, это похоже на то что стоило бы ожидать от модельки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну в целом всё, можно было сделать и лучше, ещё поиграться с моделями, попробовать всё таки запустить мою декстопную 1660 s, поиграться с Yandex Compute Cloud, там у них есть по описанию очень не плохое решение https://yandex.cloud/ru/docs/tutorials/testing/hpc-on-preemptible, ну и как я понял они халявные 4 к дают за регу + поминутная тарификация в общем чиллллллл. Да для нашей задачи это избыточно избыточно избыточно, но просто интересно. И да на самом деле, сама такска решилась за 2 часа, но на всякие штуки вокруг, я потратил ещё часов 15... но с таким интресом, в общем респект за такую дызышку, не иронична самая забавная в курсе. Ладно, я что-то тут распинаюсь а дедлайн прошел уде 11 часов назад, но переносов ещё много так что пофиг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну а что касаемо pytorch, ну тоже сделаю, раз уж начал, и в это потыкаюсь, но так как ранний дейлик не действует, то до следующей недели запушу.\n",
    "Ладно всё я наверное закалебал своими тирадами с опечатками, так что закончим, бб <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
